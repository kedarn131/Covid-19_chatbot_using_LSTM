{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8df4d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the required libraries\n",
    "\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras import layers, activations, models, preprocessing\n",
    "from tensorflow.keras import preprocessing, utils\n",
    "import os\n",
    "import re \n",
    "import pandas as pd\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import tensorflow \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import nltk.data\n",
    "import pickle\n",
    "import speech_recognition as sr\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e635ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "\n",
    "lines = open(\"dataset.txt\", encoding = 'utf-8', errors = 'ignore').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea87a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removed URLs and other unwanted objects in the text file using regular expression. \n",
    "\n",
    "lines = re.sub('https://\\S+','', lines)\n",
    "lines = re.sub('Description','', lines)\n",
    "lines = re.sub('Dialogue','', lines)\n",
    "lines = re.sub('Patient:','', lines)\n",
    "lines = re.sub('Doctor:','', lines)\n",
    "lines = re.sub('\\n\\n\\n','', lines)\n",
    "lines = re.sub(r'\\Aid', ' ', lines)\n",
    "lines = re.sub(r'[=]', '', lines)\n",
    "lines = re.sub(r'\\d', '', lines)\n",
    "new_lines = lines.split('\\n')\n",
    "#print(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3967ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1968 1968\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into question (patient) and answers (doctore).\n",
    "\n",
    "patient = []\n",
    "doctor = []\n",
    "\n",
    "for i in range(0, len(new_lines)-1, 2): \n",
    "    patient.append(new_lines[i])\n",
    "    doctor.append(new_lines[i+1])\n",
    "print(len(doctor), len(patient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4faffeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing empty rows\n",
    "while '' in patient:\n",
    "    patient.remove('')\n",
    "while '' in doctor:\n",
    "    doctor.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb5a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the list to dataframe\n",
    "pat = pd.DataFrame(patient)\n",
    "doc = pd.DataFrame(doctor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d71df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the text to lower case \n",
    "pat = pat.astype(str)\n",
    "pat[0] = pat[0].str.lower()\n",
    "#print(pat)\n",
    "doc = doc.astype(str)\n",
    "doc[0] = doc[0].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7315b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                        \n",
      "1       hello doctor, get cough last days, heavy night...\n",
      "2                   hello, understand concern. questions.\n",
      "3       phlegm lot. tiny amount comes time. difficulty...\n",
      "4       hi, would recommend take n-acetylcysteine mg p...\n",
      "                              ...                        \n",
      "1198    get coronavirus, ways avoid getting illnesses ...\n",
      "1199    plane march th home ever since self quarantine...\n",
      "1200               son fever, concerned due coronavirus ?\n",
      "1201    coronavirus symptoms mild people versus severe...\n",
      "1202    good day, weeks pregnant profession teaching, ...\n",
      "Name: 0, Length: 1203, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Removing stopwords from the text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "pat[0] = pat[0].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "#print(pat)\n",
    "doc[0] = doc[0].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "print(pat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0443d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h8/4m_c3pfj1cnd2kpvtxkflc600000gn/T/ipykernel_46293/1147321814.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  pat[0] = pat[0].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "# Stemming \n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer()\n",
    "pat[0] = pat[0].apply(lambda x: ' '.join([ps.stem(word) for word in x.split()]))\n",
    "pat[0] = pat[0].str.replace('[^\\w\\s]','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff6b9a4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h8/4m_c3pfj1cnd2kpvtxkflc600000gn/T/ipykernel_46293/1418476608.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  doc[0] = doc[0].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "doc[0] = doc[0].apply(lambda x: ' '.join([ps.stem(word) for word in x.split()]))\n",
    "doc[0] = doc[0].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3373f8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kedarnandiwdekar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/kedarnandiwdekar/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Lemmetization \n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lemmatize_words = np.vectorize(wordnet_lemmatizer.lemmatize)\n",
    "lemmatized_pat = ' '.join(lemmatize_words(pat[0]))\n",
    "lemmatized_doc = ' '.join(lemmatize_words(doc[0]))\n",
    "\n",
    "#lemmatized_pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b98de35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4103\n"
     ]
    }
   ],
   "source": [
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tok_pat = tokenizer.fit_on_texts(patient)\n",
    "v_size = len( tokenizer.word_index )+1\n",
    "print(v_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1698d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4019\n"
     ]
    }
   ],
   "source": [
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(doctor)\n",
    "v_size = len( tokenizer.word_index )+1\n",
    "print(v_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74d16906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1203, 292)\n"
     ]
    }
   ],
   "source": [
    "# Encoder input done ! \n",
    "\n",
    "patient_tokens = tokenizer.texts_to_sequences(patient) # Converting all the patient data into tokens which are then \n",
    "                                                       # arranged into sequences \n",
    "patient_max = len(patient_tokens[0]) # Calculation the maximum length of longest sequence\n",
    "for x in patient_tokens:\n",
    "    if len(x) > patient_max:\n",
    "        patient_max = len(x)\n",
    "e_data = np.array(pad_sequences(patient_tokens, maxlen = patient_max, padding = 'post')) # padding the sequences and then\n",
    "                                                                                         # converting them into numpy arrays\n",
    "print(e_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5bdf385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1203, 329) 329 (1203, 329, 4019)\n"
     ]
    }
   ],
   "source": [
    "#decoder input and decoder output \n",
    "\n",
    "doctor_tokens = tokenizer.texts_to_sequences(doctor) # Converting all the patient data into tokens which are then\n",
    "doctor_max = len(doctor_tokens[0])                   # arranged into sequences\n",
    "for x in doctor_tokens:                              # Calculation the maximum length of longest sequence\n",
    "    if len(x) > doctor_max:\n",
    "        doctor_max = len(x)\n",
    "d_data = np.array(pad_sequences( doctor_tokens, maxlen = doctor_max, padding = 'post'))\n",
    "# Applying onehotencoding\n",
    "dout_data = np.array(utils.to_categorical(pad_sequences( doctor_tokens, maxlen = doctor_max, padding = 'post'))) \n",
    "#decoder_input_data = np.array(padded_answers)\n",
    "d_data = d_data[0:1203]         # Snipping the data to fit into the encoder\n",
    "dout_data = dout_data[0:1203]   # Snipping the data to fit into the encoder\n",
    "print(d_data.shape, doctor_max, dout_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c045de8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 17:13:37.186575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from tensorflow.keras.activations import softmax\n",
    "\n",
    "e_inputs = Input(shape=(patient_max, ))                           # Creating a tensor to insert into embedder\n",
    "e_embedd = Embedding( v_size, 200 , mask_zero=True)#(e_inputs) # Creating dense vector using the tensor we just fed it\n",
    "e_emb = e_embedd(e_inputs)\n",
    "e_lstm = LSTM( 200 , return_state=True )#(e_embedd)\n",
    "e_out , e_state_h , e_state_c =  e_lstm(e_emb)# Creating encoder states which will be accessed later\n",
    "e_states = [ e_state_h , e_state_c ]\n",
    " \n",
    "d_inputs = Input(shape=( doctor_max ,  ))                        # Creating a tensor to insert into embedder \n",
    "d_embedd = Embedding( v_size, 200 , mask_zero=True) #(d_inputs) # Creating dense vector using the tensor we just fed it\n",
    "d_emb = d_embedd(d_inputs)\n",
    "d_lstm = LSTM( 200 , return_state=True , return_sequences=True ) # We created LSTM layer \n",
    "d_out , _ , _ = d_lstm ( d_emb, initial_state=e_states )   \n",
    "d_dense = Dense( v_size , activation=softmax ) # The dense layer\n",
    "d_output = d_dense ( d_out ) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1080f20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 292)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 329)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 292, 200)     803800      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 329, 200)     803800      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 329, 200),   320800      ['embedding_1[0][0]',            \n",
      "                                 (None, 200),                     'lstm[0][1]',                   \n",
      "                                 (None, 200)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 329, 4019)    807819      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,057,019\n",
      "Trainable params: 3,057,019\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 127s 5s/step - loss: 0.5726 - categorical_accuracy: 0.0442\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 116s 5s/step - loss: 0.5235 - categorical_accuracy: 0.0424\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 120s 5s/step - loss: 0.5016 - categorical_accuracy: 0.0441\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 119s 5s/step - loss: 0.4829 - categorical_accuracy: 0.0440\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 143s 6s/step - loss: 0.4693 - categorical_accuracy: 0.0481\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 120s 5s/step - loss: 0.4562 - categorical_accuracy: 0.0616\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 137s 5s/step - loss: 0.4417 - categorical_accuracy: 0.0843\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 142s 6s/step - loss: 0.4249 - categorical_accuracy: 0.1251\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 110s 4s/step - loss: 0.4035 - categorical_accuracy: 0.1745\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 111s 4s/step - loss: 0.3782 - categorical_accuracy: 0.2434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f81bbb1b790>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model building and training. \n",
    "\n",
    "from tensorflow.keras import Model\n",
    "chatbot_model = Model([e_inputs, d_inputs], d_output ) # Created the model to train\n",
    "chatbot_model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "# Compiling the model and setting up parameters for testing \n",
    "chatbot_model.summary()\n",
    "chatbot_model.fit([e_data , d_data], dout_data, batch_size=50, epochs= 10)  # Function to train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe10b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "chatbot_model.save(\"chatbot_model.h5\", chatbot_model) # Save the trained model\n",
    "model = load_model(\"chatbot_model.h5\") # Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f330d930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please tell us your query.\n",
      "Please speak again\n",
      "hello\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 329) for input KerasTensor(type_spec=TensorSpec(shape=(None, 329), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Chatbot:  to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m         s_values \u001b[38;5;241m=\u001b[39m [ h , c ]\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatbot: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m chatbot_answer )\u001b[38;5;66;03m# printing the chabot response\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     \u001b[43mSpeakText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchatbot_answer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m#engine = pyttsx3.init()\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m#engine.say(chatbot_answer)                      # Function to convert the textual bot response to speech\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m#engine.runAndWait()\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mSpeakText\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m      8\u001b[0m engine \u001b[38;5;241m=\u001b[39m pyttsx3\u001b[38;5;241m.\u001b[39minit()\n\u001b[1;32m      9\u001b[0m engine\u001b[38;5;241m.\u001b[39msay(command)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunAndWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyttsx3/engine.py:180\u001b[0m, in \u001b[0;36mEngine.runAndWait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inLoop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_driverLoop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunAndWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyttsx3/driver.py:192\u001b[0m, in \u001b[0;36mDriverProxy.runAndWait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03mCalled by the engine to start an event loop, process all commands in\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mthe queue at the start of the loop, and then exit the loop.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_push(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mendLoop, \u001b[38;5;28mtuple\u001b[39m())\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartLoop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyttsx3/drivers/nsss.py:35\u001b[0m, in \u001b[0;36mNSSpeechDriver.startLoop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstartLoop\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     33\u001b[0m     NSTimer\u001b[38;5;241m.\u001b[39mscheduledTimerWithTimeInterval_target_selector_userInfo_repeats_(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monPumpFirst:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mAppHelper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunConsoleEventLoop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/PyObjCTools/AppHelper.py:263\u001b[0m, in \u001b[0;36mrunConsoleEventLoop\u001b[0;34m(argv, installInterrupt, mode, maxTimeout)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m nextfire \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m             nextfire \u001b[38;5;241m=\u001b[39m soon\u001b[38;5;241m.\u001b[39mearlierDate_(nextfire)\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mrunLoop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunMode_beforeDate_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnextfire\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    264\u001b[0m             stopper\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyttsx3/drivers/nsss.py:109\u001b[0m, in \u001b[0;36mNSSpeechDriver.speechSynthesizer_willSpeakWord_ofString_\u001b[0;34m(self, tts, rng, text)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxy\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinished-utterance\u001b[39m\u001b[38;5;124m'\u001b[39m, completed\u001b[38;5;241m=\u001b[39msuccess)\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxy\u001b[38;5;241m.\u001b[39msetBusy(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspeechSynthesizer_willSpeakWord_ofString_\u001b[39m(\u001b[38;5;28mself\u001b[39m, tts, rng, text):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxy\u001b[38;5;241m.\u001b[39mnotify(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarted-word\u001b[39m\u001b[38;5;124m'\u001b[39m, location\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mlocation,\n\u001b[1;32m    111\u001b[0m                        length\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mlength)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "r = sr.Recognizer() # Creating an instance for the listener, to listen to our speech \n",
    "tokens_list = list() \n",
    "\n",
    "def SpeakText(command):  # Initializing the listener engine \n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(command)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "\n",
    "d_state_h = Input(shape=( 200 ,))       # Initializing decoder state h\n",
    "d_state_c = Input(shape=( 200 ,))       # Initializing decoder state c\n",
    "d_states_in = [d_state_h, d_state_c]                    # Combining them, so as to feed it into the lstm layer\n",
    "d_out, s_h, s_c = d_lstm(d_emb , initial_state=d_states_in) # lstm layer with embedded user input and initial states\n",
    "d_states = [s_h, s_c]                                   # saving new states created after lstm layer\n",
    "d_out = d_dense(d_out)                                  # feeding the output of the lstm into the dense layer. \n",
    "model_d = Model([d_inputs] + d_states_in,[d_out] + d_states)  # Creating the decoder model\n",
    "model_e = Model(e_inputs, e_states)                     # Encoder model with initial states for user input\n",
    "\n",
    "print(\"Please tell us your query.\")\n",
    "while (True):                                           # Creating the loop to keep running the chatbot\n",
    "    try:\n",
    "        # For speech to text to speech, initiating engines \n",
    "        with sr.Microphone() as source2:\n",
    "            r.adjust_for_ambient_noise(source2, duration=0.2) # Adjusting for surrounding noise\n",
    "            audio2 = r.listen(source2)                        # Listening to the human speech\n",
    "            MyText = r.recognize_google(audio2)               # Converting the speech to text \n",
    "            MyText = MyText.lower()                           # converting the text to all lower case \n",
    "            print(MyText)\n",
    "        words = MyText.lower().split()# Splitting the words in the text\n",
    "        w_len = len(words)\n",
    "        for i in range(0, (w_len-1)):\n",
    "            w = words[i]\n",
    "            tokens_list.append( tokenizer.word_index[ w ] ) # Tokeninzing the words\n",
    "        user_input_padded = pad_sequences( [tokens_list] , maxlen=patient_max, padding='post') # padding the sequence\n",
    "        s_values = model_e.predict(user_input_padded) # Feeding the padded sequence into the encoder model for prediction\n",
    "        #s_values = model_e.predict( text_convert(MyText))\n",
    "        t_seq = np.zeros( ( 1 , 1 ) )                         # Creating an matrix of 1's\n",
    "        t_seq[0, 0] = tokenizer.word_index['start']           # tokenizing 'start' word at 0,0 position in the matrix\n",
    "        quit_chatbot = 0                                      # initializing variable to shut the chatbot\n",
    "        chatbot_answer = ''                                   # initializing the string to store chatbot response\n",
    "        while quit_chatbot == 0:                              # Setting chatbot quit condition to not true \n",
    "            d_o , h , c = model_d.predict([ t_seq ] + s_values ) # Taking the decoder output with the updated states \n",
    "                                           # The inputs gone through the encoder to the decoder changing the decoder states.\n",
    "                                           # the output states here are the updated deoder states\n",
    "            s_index = np.argmax( d_o[0, -1, :] ) # Converting the output of the decoder into word index \n",
    "            s_word = None                        # Setting sample word to none\n",
    "            for w , i in tokenizer.word_index.items() : # Iterating throughout the indexes till we get a match for the words. \n",
    "                if s_index == i :\n",
    "                    chatbot_answer += ' {}'.format( w ) # converting the indexes into the matching words and formulating the response\n",
    "                    s_word = w\n",
    "            if s_word == 'end' or len(chatbot_answer.split()) > doctor_max: # if the formulated word is end, chabot quit condition \n",
    "                                                                            # becomes true\n",
    "                quit_chatbot = 1                                            # Chabot quit condition turns true\n",
    "            new_t_seq = np.zeros( ( 1 , 1 ) )            # Resetting the matrix to only 1's for the new input. \n",
    "            new_t_seq[ 0 , 0 ] = s_index\n",
    "            t_seq = new_t_seq\n",
    "            s_values = [ h , c ]\n",
    "        print(\"Chatbot: \" + chatbot_answer )# printing the chabot response\n",
    "        SpeakText(chatbot_answer)\n",
    "        #engine = pyttsx3.init()\n",
    "        #engine.say(chatbot_answer)                      # Function to convert the textual bot response to speech\n",
    "        #engine.runAndWait()\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results; {0}\".format(e))\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Please speak again\")                    # Error handling, in case the human speech is not recognized. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8014da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References that were used to build this chatbot \n",
    "# https://numpy.org/\n",
    "# https://pypi.org/project/numpy/\n",
    "# https://pypi.org/project/tensorflow/\n",
    "# https://keras.io/api/layers/recurrent_layers/lstm/\n",
    "# https://keras.io/api/models/\n",
    "# A. Graves, A.-R. Mohamed, & G. Hinton. (n.d.). Speech Recognition with Deep Recurrent Neural Networks.\n",
    "# Eslam, A., Ahmed , H., Omar , F., Albert , L., Youssef , M., & Michel , A. (2021). A Proposed Chatbot Framework for COVID-19. Cairo: IEEE.\n",
    "# https://github.com/ShrishtiHore/Conversational_Chatbot_using_LSTM\n",
    "# Wani, G. D. (2018). TEXT NORMALIZATION FOR SPEECH RECOGNITION USING DEEP LEARNING. California : California State University.\n",
    "# El Hefny, W., El Bolock, A., Herbert, C., & Abdennadher, S. (2021). Chase Away the Virus: A Character-Based Chatbot for COVID-19. IEEE 2021.\n",
    "# https://www.icliniq.com/qa/covid-19/i-have-cough-with-no-travel-history-is-this-a-symptoms-of-covid-19\n",
    "# https://keras.io/api/losses/\n",
    "# https://www.nltk.org/\n",
    "# https://pypi.org/project/nltk/\n",
    "# https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/\n",
    "# https://flask.palletsprojects.com/en/2.2.x/\n",
    "# https://www.tutorialspoint.com/flask/index.htm\n",
    "# https://www.thepythoncode.com/article/using-speech-recognition-to-convert-speech-to-text-python\n",
    "# https://www.analyticsvidhya.com/blog/2020/04/how-to-deploy-machine-learning-model-flask/\n",
    "# Boyd, C. (2018). The Past Present and the Future of Speech Recognition Technology. Medium.\n",
    "# Grinberg, M. (n.d.). Flask Web Development: Developing Web Applications with Python. O'Reilly.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
